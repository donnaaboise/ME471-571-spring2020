{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "# Using a pool of workers\n",
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "In many situations we have J jobs to do and P processors available.  If each job takes $T_j$ time, it would helpful to have an automated procedure for launching jobs on processes in such a way that each process uses approximately $W_p$ total work, where\n",
    "\n",
    "\\begin{equation*}\n",
    "W_p \\approx \\frac{1}{P}\\sum_{j=1}^J T_j \\qquad p = 1,2,...,P\n",
    "\\end{equation*}\n",
    "\n",
    "The `multiprocessing` module's Pool object solves this problem.   \n",
    "\n",
    "If we have several jobs which we expect to take unequal lengths of time to process, we can use a *pool* of workers.  The advantage of this approach is that the processes will be automatically launched, and results automatically collected and returned.  The steps in launching a pool are as follows : \n",
    "\n",
    "1.  Decide on how many *tasks* should be launched (`njobs`)\n",
    "\n",
    "2.  Decide on how many *processes* should be launched (`nprocs`)\n",
    "\n",
    "3.  Define functions that should be called when defining a worker process or processes (`worker`).  \n",
    "\n",
    "4.  Launch the pool of workers.  There are two conceptual ways to launch jobs:\n",
    "\n",
    "    * Use `apply` or `apply_async`.  This will launch a single job, with a single argument, using a process from the pool.   Multiple processes can be launched with multiple calls to `apply` or `apply_async`. \n",
    "    \n",
    "    * Use `map` or `map_async`.  This will launch multiple jobs to run the same task on an  *iterable* object (array, list, zip object, and so on).  \n",
    "    \n",
    "Here are four sample codes.  The function to be applied in each case is `f`, with an array of `njobs` tuples `data`.  In each case, the Pool is defined as\n",
    "<pre><code>\n",
    "pool = multiprocessing.Pool(processes=nprocs)\n",
    "</code></pre>\n",
    "\n",
    "For all examples, the results from all processes are stored in `results`. \n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 1 : Blocking code using `Pool.map`\n",
    "\n",
    "<pre><code>\n",
    "# Blocks until all results are ready\n",
    "results = pool.map(func=f, iterable=data)\n",
    "</code></pre>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 2 : Non-blocking code using `Pool.map_async`\n",
    "Results can be processed as they become available using a `callback` function.\n",
    "\n",
    "<pre><code>\n",
    "# Non-blocking code.  Results can be processed by a callback.\n",
    "async_results = pool.map_async(func=f, iterable=data, \n",
    "    callback=cb)\n",
    "\n",
    "# Blocks until results are ready\n",
    "results = async_results.get()    \n",
    "</code></pre>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 3 : Blocking code using `Pool.apply`\n",
    "Code will run sequentially - probably not what we want for parallel computing!\n",
    "<html><pre><code>\n",
    "results = []\n",
    "for d in data:\n",
    "    # Blocks until job is done\n",
    "    r = pool.apply(func=worker, args=(d,))        \n",
    "    results.append(r)\n",
    "</code></pre></html>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 4 :  Non-blocking code using `Pool.apply_async`\n",
    "We can use a `callback` to process the results as they become available.\n",
    "<pre><code>\n",
    "async_results = []\n",
    "for d in data:\n",
    "    # Non-blocking calls\n",
    "    r = pool.apply_async(func=f,args=(d,),callback=cb)\n",
    "    async_results.append(r)\n",
    "    \n",
    "# Blocks until results are ready \n",
    "results = [r.get() for r in async_results] \n",
    "</code></pre>\n",
    "\n",
    "Two additional examples illustrate how to distribute tasks using `chunksize` (Example 5) and how to use a callback function to process results as they become \n",
    "available (Example 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Sample results explained\n",
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following results are typical results obtained using the `Pool.map_async` call.\n",
    "<pre><code>\n",
    "Launching 19 jobs on 8 cores\n",
    "In process 4916 ( 0) is sleeping   4.8323 seconds\n",
    "In process 4918 ( 2) is sleeping   0.0375 seconds\n",
    "In process 4921 ( 5) is sleeping   2.9111 seconds\n",
    "In process 4917 ( 1) is sleeping   2.2037 seconds\n",
    "In process 4922 ( 6) is sleeping   3.3578 seconds\n",
    "In process 4920 ( 4) is sleeping   4.6963 seconds\n",
    "In process 4919 ( 3) is sleeping   4.5549 seconds\n",
    "In process 4923 ( 7) is sleeping   0.4197 seconds\n",
    "In process 4918 ( 8) is sleeping   3.8324 seconds\n",
    "In process 4923 ( 9) is sleeping   1.1840 seconds\n",
    "In process 4923 (10) is sleeping   0.1541 seconds\n",
    "In process 4923 (11) is sleeping   3.9439 seconds\n",
    "In process 4917 (12) is sleeping   1.7304 seconds\n",
    "In process 4921 (13) is sleeping   3.1164 seconds\n",
    "In process 4922 (14) is sleeping   3.0791 seconds\n",
    "In process 4918 (15) is sleeping   0.7428 seconds\n",
    "In process 4917 (16) is sleeping   0.9155 seconds\n",
    "In process 4919 (17) is sleeping   0.5721 seconds\n",
    "In process 4918 (18) is sleeping   0.0731 seconds\n",
    "<br/>\n",
    "Total time spent in each process\n",
    "Process  1 (4916)    4.8323(s)    1 job(s) (0,)\n",
    "Process  2 (4917)    4.8496(s)    3 job(s) (1, 12, 16)\n",
    "Process  3 (4918)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
    "Process  4 (4919)    5.1269(s)    2 job(s) (3, 17)\n",
    "Process  5 (4920)    4.6963(s)    1 job(s) (4,)\n",
    "Process  6 (4921)    6.0275(s)    2 job(s) (5, 13)\n",
    "Process  7 (4922)    6.4369(s)    2 job(s) (6, 14)\n",
    "Process  8 (4923)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
    "\n",
    "      Total work done (s)      42.3570\n",
    "      Wall clock time (s)       6.4890\n",
    "</code></pre>\n",
    "The first set of results (19 lines) is printed for each job launched and \n",
    "provides the process PID (decided by the OS), the task number (0-18), and the time spent in each job.   This information is printed as jobs are launched. \n",
    "\n",
    "The second set of results (8 lines) collects process information and provides the processor number (1-8) and PID, the total time spent in that process, the number of jobs launched on that processor, and the job numbers launched on that processor.\n",
    "\n",
    "**Observations.** The first set of results (first 19 lines) are printed as jobs are launched and illustrates the `asynchronous` nature of the call.  Jobs do not necessarily start processing as soon as they are launched.  For example, jobs 2 and 5 are started before job 1.  On the other hand, if we were to sort this list on job number, we would see that jobs are launched on our 8 processors in order.  Here are the first several jobs taken from the top of a list sorted on job number. \n",
    "\n",
    "<pre><code>\n",
    "In process 4916 ( 0) is sleeping   4.8323 seconds\n",
    "In process 4917 ( 1) is sleeping   2.2037 seconds\n",
    "In process 4918 ( 2) is sleeping   0.0375 seconds\n",
    "In process 4919 ( 3) is sleeping   4.5549 seconds\n",
    "In process 4920 ( 4) is sleeping   4.6963 seconds\n",
    "In process 4921 ( 5) is sleeping   2.9111 seconds\n",
    "In process 4922 ( 6) is sleeping   3.3578 seconds\n",
    "In process 4923 ( 7) is sleeping   0.4197 seconds\n",
    "In process 4918 ( 8) is sleeping   3.8324 seconds\n",
    "In process 4923 ( 9) is sleeping   1.1840 seconds\n",
    "....\n",
    "</code></pre>\n",
    "The first 8 jobs (jobnums 0-7) are launched in order on processors 4916-4923, but the 9th job (jobnum=8) is launched on process 4918, the first processor available (jobs on 4916 and 4917 were still processing).  Similarly, job 10 (jobnum=9) is launched on the next avalailable processor 4923.\n",
    "\n",
    "Post-processing the results (second 8 lines), we see that to achieve approximately the same amount of time per processor (i.e. *load balancing*), jobs are distributed unequally.  To achieve an approximate time of 5s per process, processors 1 and 5 were only able to processs 1 job, whereas processors 3 and 8 were able to process 4 jobs each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Python modules used for all examples\n",
    "\n",
    "The following creates and saves the module `pool_tools.py`, used by all example.   The magic command `%%file` creates the indicated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pool_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%file pool_tools.py\n",
    "from multiprocessing import Pool\n",
    "import time, os, random\n",
    "\n",
    "def worker(z):\n",
    "    jobnum, t = z    # Distribute tuple to variables.\n",
    "    id = os.getpid()\n",
    "    print(\"In process {} ({:2d}) is sleeping {:8.4f} seconds\".format(id,jobnum,t))\n",
    "    time.sleep(t)\n",
    "    return (jobnum,t,os.getpid())\n",
    "\n",
    "def print_pool_results(res,np):\n",
    "    # how much time was spent in each process? \n",
    "    pids = sorted(set([z[2] for z in res]))    # Get a unique set of PIDs\n",
    "    print(\"\")\n",
    "    print(\"Total time spent in each process\")\n",
    "    total_time = 0\n",
    "    for i,p in enumerate(pids):\n",
    "        proc_count = sum([1 for z in res if z[2] == p])\n",
    "        proc_time  = sum([z[1] for z in res if z[2] == p])\n",
    "        proc_jobs  = tuple([z[0] for z in res if z[2] == p])\n",
    "        print(\"Process {:2d} ({})  {:8.4f}(s) {:4d} job(s) {}\"\n",
    "              .format(i+1,p,proc_time,proc_count,proc_jobs))\n",
    "        total_time += proc_time\n",
    "    print(\"\")\n",
    "    print(\"{:>25s} {:12.4f}\".format(\"Total work done (s)\",total_time))                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Example 1 : pool.map(func=f,iterable=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 94715 ( 0) is sleeping   4.8323 seconds\n",
      "In process 94716 ( 1) is sleeping   2.2037 seconds\n",
      "In process 94717 ( 2) is sleeping   0.0375 seconds\n",
      "In process 94718 ( 3) is sleeping   4.5549 seconds\n",
      "In process 94719 ( 4) is sleeping   4.6963 seconds\n",
      "In process 94720 ( 5) is sleeping   2.9111 seconds\n",
      "In process 94721 ( 6) is sleeping   3.3578 seconds\n",
      "In process 94722 ( 7) is sleeping   0.4197 seconds\n",
      "In process 94717 ( 8) is sleeping   3.8324 seconds\n",
      "In process 94722 ( 9) is sleeping   1.1840 seconds\n",
      "In process 94722 (10) is sleeping   0.1541 seconds\n",
      "In process 94722 (11) is sleeping   3.9439 seconds\n",
      "In process 94716 (12) is sleeping   1.7304 seconds\n",
      "In process 94720 (13) is sleeping   3.1164 seconds\n",
      "In process 94721 (14) is sleeping   3.0791 seconds\n",
      "In process 94717 (15) is sleeping   0.7428 seconds\n",
      "In process 94716 (16) is sleeping   0.9155 seconds\n",
      "In process 94718 (17) is sleeping   0.5721 seconds\n",
      "In process 94717 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (94715)    4.8323(s)    1 job(s) (0,)\n",
      "Process  2 (94716)    4.8496(s)    3 job(s) (1, 12, 16)\n",
      "Process  3 (94717)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
      "Process  4 (94718)    5.1269(s)    2 job(s) (3, 17)\n",
      "Process  5 (94719)    4.6963(s)    1 job(s) (4,)\n",
      "Process  6 (94720)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (94721)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (94722)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)       6.4918\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test1(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "\n",
    "    # This function blocks until results are available\n",
    "    results = pool.map(func=worker,iterable=data)\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test1(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Example 2 : pool.map_async(func=f,iterable=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 94739 ( 1) is sleeping   2.2037 seconds\n",
      "In process 94740 ( 2) is sleeping   0.0375 seconds\n",
      "In process 94741 ( 3) is sleeping   4.5549 seconds\n",
      "In process 94738 ( 0) is sleeping   4.8323 seconds\n",
      "In process 94742 ( 4) is sleeping   4.6963 seconds\n",
      "In process 94744 ( 6) is sleeping   3.3578 seconds\n",
      "In process 94743 ( 5) is sleeping   2.9111 seconds\n",
      "In process 94745 ( 7) is sleeping   0.4197 seconds\n",
      "In process 94740 ( 8) is sleeping   3.8324 seconds\n",
      "In process 94745 ( 9) is sleeping   1.1840 seconds\n",
      "In process 94745 (10) is sleeping   0.1541 seconds\n",
      "In process 94745 (11) is sleeping   3.9439 seconds\n",
      "In process 94739 (12) is sleeping   1.7304 seconds\n",
      "In process 94743 (13) is sleeping   3.1164 seconds\n",
      "In process 94744 (14) is sleeping   3.0791 seconds\n",
      "In process 94740 (15) is sleeping   0.7428 seconds\n",
      "In process 94739 (16) is sleeping   0.9155 seconds\n",
      "In process 94741 (17) is sleeping   0.5721 seconds\n",
      "In process 94740 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (94738)    4.8323(s)    1 job(s) (0,)\n",
      "Process  2 (94739)    4.8496(s)    3 job(s) (1, 12, 16)\n",
      "Process  3 (94740)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
      "Process  4 (94741)    5.1269(s)    2 job(s) (3, 17)\n",
      "Process  5 (94742)    4.6963(s)    1 job(s) (4,)\n",
      "Process  6 (94743)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (94744)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (94745)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)       6.4856\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test2(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "    \n",
    "    # This is non-blocking\n",
    "    async_results = pool.map_async(func=worker,iterable=data)\n",
    "    \n",
    "    # This call blocks until all results are available\n",
    "    results = async_results.get()   \n",
    "    \n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test2(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Example 3 : pool.apply(func = f,args = data)\n",
    "\n",
    "Using this mode, jobs are launched in order and run sequentially.  Jobs are not run in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 94778 ( 0) is sleeping   4.8323 seconds\n",
      "In process 94779 ( 1) is sleeping   2.2037 seconds\n",
      "In process 94780 ( 2) is sleeping   0.0375 seconds\n",
      "In process 94781 ( 3) is sleeping   4.5549 seconds\n",
      "In process 94782 ( 4) is sleeping   4.6963 seconds\n",
      "In process 94783 ( 5) is sleeping   2.9111 seconds\n",
      "In process 94784 ( 6) is sleeping   3.3578 seconds\n",
      "In process 94785 ( 7) is sleeping   0.4197 seconds\n",
      "In process 94778 ( 8) is sleeping   3.8324 seconds\n",
      "In process 94779 ( 9) is sleeping   1.1840 seconds\n",
      "In process 94780 (10) is sleeping   0.1541 seconds\n",
      "In process 94781 (11) is sleeping   3.9439 seconds\n",
      "In process 94782 (12) is sleeping   1.7304 seconds\n",
      "In process 94783 (13) is sleeping   3.1164 seconds\n",
      "In process 94784 (14) is sleeping   3.0791 seconds\n",
      "In process 94785 (15) is sleeping   0.7428 seconds\n",
      "In process 94778 (16) is sleeping   0.9155 seconds\n",
      "In process 94779 (17) is sleeping   0.5721 seconds\n",
      "In process 94780 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (94778)    9.5801(s)    3 job(s) (0, 8, 16)\n",
      "Process  2 (94779)    3.9598(s)    3 job(s) (1, 9, 17)\n",
      "Process  3 (94780)    0.2646(s)    3 job(s) (2, 10, 18)\n",
      "Process  4 (94781)    8.4987(s)    2 job(s) (3, 11)\n",
      "Process  5 (94782)    6.4268(s)    2 job(s) (4, 12)\n",
      "Process  6 (94783)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (94784)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (94785)    1.1625(s)    2 job(s) (7, 15)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)      42.4987\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test3(data,np):\n",
    "    pool = Pool(processes=np)          \n",
    "\n",
    "    results = []\n",
    "    for d in data:\n",
    "        # This call is blocking;  jobs run sequentially\n",
    "        r = pool.apply(worker,args=(d,))\n",
    "        results.append(r)\n",
    "    \n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test3(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Example 4 : pool.apply_async(func=data,args=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 94833 ( 0) is sleeping   4.8323 seconds\n",
      "In process 94834 ( 1) is sleeping   2.2037 seconds\n",
      "In process 94837 ( 4) is sleeping   4.6963 seconds\n",
      "In process 94836 ( 3) is sleeping   4.5549 seconds\n",
      "In process 94838 ( 5) is sleeping   2.9111 seconds\n",
      "In process 94835 ( 2) is sleeping   0.0375 seconds\n",
      "In process 94839 ( 6) is sleeping   3.3578 seconds\n",
      "In process 94840 ( 7) is sleeping   0.4197 seconds\n",
      "In process 94835 ( 8) is sleeping   3.8324 seconds\n",
      "In process 94840 ( 9) is sleeping   1.1840 seconds\n",
      "In process 94840 (10) is sleeping   0.1541 seconds\n",
      "In process 94840 (11) is sleeping   3.9439 seconds\n",
      "In process 94834 (12) is sleeping   1.7304 seconds\n",
      "In process 94838 (13) is sleeping   3.1164 seconds\n",
      "In process 94839 (14) is sleeping   3.0791 seconds\n",
      "In process 94835 (15) is sleeping   0.7428 seconds\n",
      "In process 94834 (16) is sleeping   0.9155 seconds\n",
      "In process 94836 (17) is sleeping   0.5721 seconds\n",
      "In process 94835 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (94833)    4.8323(s)    1 job(s) (0,)\n",
      "Process  2 (94834)    4.8496(s)    3 job(s) (1, 12, 16)\n",
      "Process  3 (94835)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
      "Process  4 (94836)    5.1269(s)    2 job(s) (3, 17)\n",
      "Process  5 (94837)    4.6963(s)    1 job(s) (4,)\n",
      "Process  6 (94838)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (94839)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (94840)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)       6.6039\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test4(data,np):\n",
    "    pool = Pool(processes=np)             \n",
    "\n",
    "    # This call is non-blocking;  \n",
    "    async_results = []\n",
    "    for d in data:\n",
    "        r = pool.apply_async(worker,args = (d,))\n",
    "        async_results.append(r)\n",
    "    pool.close()\n",
    "    pool.join()     # Block here or with r.get() below\n",
    "    results = [r.get() for r in async_results]  # this blocks if pool is not closed/joined\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test4(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Example 5 : Controlling how tasks are distributed\n",
    "\n",
    "We can have some control over how tasks are handed off to processors using the `chunksize` keyword.  Setting `chunksize=4` when calling `map_async` for example, the pool will put the first four tasks on the first processor, the second four tasks on the second processor, and so on.  \n",
    "\n",
    "Increasing the chunksize from the default value of 1 can improve performance, depending on the application.\n",
    "\n",
    "If not done with some reasonable care, increasing chunksize can have the following disadvantages : \n",
    "\n",
    "* This can lead to very bad load balancing.\n",
    "* Some processors in the pool may not get used at all.\n",
    "\n",
    "In the following example, we create 23 tasks for 8 processors, with a chunksize of 4.  With this configuration, 5 processors will get 4 tasks each, 1 processor will get 3 tasks, and 2 processors will remain idle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 94978 ( 0) is sleeping   4.8323 seconds\n",
      "In process 94979 ( 4) is sleeping   4.6963 seconds\n",
      "In process 94980 ( 8) is sleeping   3.8324 seconds\n",
      "In process 94981 (12) is sleeping   1.7304 seconds\n",
      "In process 94982 (16) is sleeping   0.9155 seconds\n",
      "In process 94982 (17) is sleeping   0.5721 seconds\n",
      "In process 94982 (18) is sleeping   0.0731 seconds\n",
      "In process 94981 (13) is sleeping   3.1164 seconds\n",
      "In process 94980 ( 9) is sleeping   1.1840 seconds\n",
      "In process 94979 ( 5) is sleeping   2.9111 seconds\n",
      "In process 94978 ( 1) is sleeping   2.2037 seconds\n",
      "In process 94981 (14) is sleeping   3.0791 seconds\n",
      "In process 94980 (10) is sleeping   0.1541 seconds\n",
      "In process 94980 (11) is sleeping   3.9439 seconds\n",
      "In process 94978 ( 2) is sleeping   0.0375 seconds\n",
      "In process 94978 ( 3) is sleeping   4.5549 seconds\n",
      "In process 94979 ( 6) is sleeping   3.3578 seconds\n",
      "In process 94981 (15) is sleeping   0.7428 seconds\n",
      "In process 94979 ( 7) is sleeping   0.4197 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (94978)   11.6283(s)    4 job(s) (0, 1, 2, 3)\n",
      "Process  2 (94979)   11.3850(s)    4 job(s) (4, 5, 6, 7)\n",
      "Process  3 (94980)    9.1144(s)    4 job(s) (8, 9, 10, 11)\n",
      "Process  4 (94981)    8.6687(s)    4 job(s) (12, 13, 14, 15)\n",
      "Process  5 (94982)    1.5606(s)    3 job(s) (16, 17, 18)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)      11.6826\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import  *\n",
    "\n",
    "def test5(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "\n",
    "    # This function blocks until results 'res' are available\n",
    "    async_results = pool.map_async(func=worker,iterable=data,chunksize=4)\n",
    "    results = async_results.get()\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test5(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Example 6 : Using a callback to process results\n",
    "\n",
    "In this example, we use a callback to process results as they become available.  Notice that results are available even before all jobs have been launched.  Also in this example, we illustrate the idea that the main program can be doing work while we are waiting for all jobs to complete. \n",
    "\n",
    "The callback takes the result returned from our worker process and computes both the total job time (`rt`) taken so far, and total wall-clock (`wc`) time.  Since we are running on multiple processors, we expect `rt` $>$ `wc`. \n",
    "\n",
    "**Note:**  For this example, we have increased the time spent in each process to some value in $[0,30]$ (rather than $[0,5]$ in previous examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 95005 ( 4) is sleeping  28.1781 seconds\n",
      "In process 95002 ( 1) is sleeping  13.2220 seconds\n",
      "In process 95001 ( 0) is sleeping  28.9936 seconds\n",
      "In process 95006 ( 5) is sleeping  17.4668 seconds\n",
      "In process 95004 ( 3) is sleeping  27.3293 seconds\n",
      "In process 95007 ( 6) is sleeping  20.1469 seconds\n",
      "In process 95003 ( 2) is sleeping   0.2247 seconds\n",
      "In process 95008 ( 7) is sleeping   2.5181 seconds\n",
      "---> Do some useful work while we are waiting for background jobs.\n",
      "In process 95003 ( 8) is sleeping  22.9944 seconds\n",
      "Process 95003, job  2 is done in   0.2247 (s) (wc/rt     0.27/0.22)\n",
      "In process 95008 ( 9) is sleeping   7.1043 seconds\n",
      "Process 95008, job  7 is done in   2.5181 (s) (wc/rt     2.57/2.74)\n",
      "In process 95008 (10) is sleeping   0.9244 seconds\n",
      "Process 95008, job  9 is done in   7.1043 (s) (wc/rt     9.68/9.85)\n",
      "In process 95008 (11) is sleeping  23.6632 seconds\n",
      "Process 95008, job 10 is done in   0.9244 (s) (wc/rt    10.60/10.77)\n",
      "In process 95002 (12) is sleeping  10.3827 seconds\n",
      "Process 95002, job  1 is done in  13.2220 (s) (wc/rt    13.27/23.99)\n",
      "In process 95006 (13) is sleeping  18.6984 seconds\n",
      "Process 95006, job  5 is done in  17.4668 (s) (wc/rt    17.51/41.46)\n",
      "In process 95007 (14) is sleeping  18.4745 seconds\n",
      "Process 95007, job  6 is done in  20.1469 (s) (wc/rt    20.19/61.61)\n",
      "In process 95003 (15) is sleeping   4.4566 seconds\n",
      "Process 95003, job  8 is done in  22.9944 (s) (wc/rt    23.27/84.60)\n",
      "In process 95002 (16) is sleeping   5.4927 seconds\n",
      "Process 95002, job 12 is done in  10.3827 (s) (wc/rt    23.66/94.98)\n",
      "---> Done with our other work !!!\n",
      "In process 95004 (17) is sleeping   3.4324 seconds\n",
      "Process 95004, job  3 is done in  27.3293 (s) (wc/rt    27.38/122.31)\n",
      "In process 95003 (18) is sleeping   0.4386 seconds\n",
      "Process 95003, job 15 is done in   4.4566 (s) (wc/rt    27.73/126.77)\n",
      "Process 95003, job 18 is done in   0.4386 (s) (wc/rt    28.17/127.21)\n",
      "Process 95005, job  4 is done in  28.1781 (s) (wc/rt    28.23/155.39)\n",
      "Process 95001, job  0 is done in  28.9936 (s) (wc/rt    29.04/184.38)\n",
      "Process 95002, job 16 is done in   5.4927 (s) (wc/rt    29.15/189.87)\n",
      "Process 95004, job 17 is done in   3.4324 (s) (wc/rt    30.81/193.31)\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "# Process results right away.\n",
    "running_total = 0\n",
    "def cb(res):\n",
    "    global t0, running_total\n",
    "    r = res\n",
    "    t1 = time.time()\n",
    "    wc = t1-t0\n",
    "    running_total += r[1]\n",
    "    print(\"Process {}, job {:2d} is done in {:8.4f} (s) (wc/rt {:8.2f}/{:.2f})\".\n",
    "          format(r[2],r[0],r[1],wc,running_total))\n",
    "\n",
    "def test6(data,np):\n",
    "    pool = Pool(processes=np)              # start 4 worker processes\n",
    "\n",
    "    # This call is non-blocking;  \n",
    "    async_results = []\n",
    "    for d in data:\n",
    "        r = pool.apply_async(func=worker, args=(d,), callback=cb)\n",
    "        async_results.append(r)\n",
    "    pool.close()\n",
    "    print(\"---> Do some useful work while we are waiting for background jobs.\")\n",
    "    time.sleep(25)\n",
    "    print(\"---> Done with our other work !!!\")\n",
    "    pool.join()     # Block here or with r.get() below\n",
    "    results = [r.get() for r in async_results]  # this blocks if pool is not closed/joined\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [30*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "t0 = time.time()\n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test6(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr style=\"border-width:4px; border-color:coral; border-style:solid\" hr/>\n",
    "\n",
    "## Example 7 : Using a Process\n",
    "\n",
    "In this example, we use the original multiprocessing Process to fork processes. \n",
    "As the results show, the underlying operating system may be the best scheduler! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pool_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f46fc7db59ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpool_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pool_tools'"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "from multiprocessing import Pool, Process, Pipe\n",
    "import time, os, random\n",
    "\n",
    "def worker_pipe(d,p1):\n",
    "    jobnum, t = d    # Distribute tuple to variables.\n",
    "    id = os.getpid()\n",
    "    print(\"In process {} ({:2d}) is sleeping {:8.4f} seconds\".format(id,jobnum,t))\n",
    "    time.sleep(t)\n",
    "    p1.send((jobnum,t,os.getpid()))\n",
    "\n",
    "    \n",
    "def test7(data,np):\n",
    "    pool = Pool(processes=np)              # start 4 worker processes\n",
    "\n",
    "    jobs = []\n",
    "    pipes = []\n",
    "    for d in data:\n",
    "        p0,p1 = Pipe()\n",
    "        job = Process(target=worker_pipe,args=(d,p1))\n",
    "        job.start()\n",
    "        jobs.append(job)\n",
    "        pipes.append(p0)\n",
    "        \n",
    "    results = []\n",
    "    for p1 in pipes:\n",
    "        r = p1.recv()\n",
    "        results.append(r)\n",
    "        p1.close()\n",
    "        \n",
    "    print_pool_results(results,np)\n",
    "\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [30*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "t0 = time.time()\n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test7(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
