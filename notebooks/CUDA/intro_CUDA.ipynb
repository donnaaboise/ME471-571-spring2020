{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "## Simple CUDA programs\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "The simplest possible GPU program launches a single kernel with a single thread.  The kernel designation `__global__` indicates that the function `kernel` can be launched from the nost (the CPU, in this case). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing demo_00.cu\n"
     ]
    }
   ],
   "source": [
    "%%file demo_00.cu\n",
    "\n",
    "__global__ void kernel( void ) \n",
    "{\n",
    "    ;\n",
    "}\n",
    "\n",
    "int main(void) \n",
    "{\n",
    "    /* Launch a single thread on one block */\n",
    "    kernel<<<1,1>>>();\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "nvcc -o demo_00 demo_00.cu\n",
    "\n",
    "srun demo_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px; border-color:black\"></hr>\n",
    "In a slightly more complicated program, we use the hardwired index of the block and thread for the kernel launch.\n",
    "\n",
    "A kernel launch is *asynchronous*, meaning that as soon as the kernel is launched, the CPU code continues.  For this simple program, the CPU code will finish before the GPU kernel is completed.  To force the device to wait, we include the command \n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demo_01.cu\n"
     ]
    }
   ],
   "source": [
    "%%file demo_01.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void kernel( void ) \n",
    "{\n",
    "    int ix = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    printf(\"Thread %d; Block %d : Hello, World from global thread index %d\\n\", threadIdx.x, blockIdx.x,ix);\n",
    "}\n",
    "\n",
    "int main(void) \n",
    "{\n",
    "    dim3 grid(3);\n",
    "    dim3 block(4);\n",
    "    kernel<<<grid,block>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0; Block 0 : Hello, World from global thread index 0\n",
      "Thread 1; Block 0 : Hello, World from global thread index 1\n",
      "Thread 2; Block 0 : Hello, World from global thread index 2\n",
      "Thread 3; Block 0 : Hello, World from global thread index 3\n",
      "Thread 0; Block 2 : Hello, World from global thread index 8\n",
      "Thread 1; Block 2 : Hello, World from global thread index 9\n",
      "Thread 2; Block 2 : Hello, World from global thread index 10\n",
      "Thread 3; Block 2 : Hello, World from global thread index 11\n",
      "Thread 0; Block 1 : Hello, World from global thread index 4\n",
      "Thread 1; Block 1 : Hello, World from global thread index 5\n",
      "Thread 2; Block 1 : Hello, World from global thread index 6\n",
      "Thread 3; Block 1 : Hello, World from global thread index 7\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "nvcc  -o demo_01 demo_01.cu\n",
    "\n",
    "# On R2 : We need to specify the 'gpu' partition (i.e. the queue). \n",
    "srun -p gpuq demo_01\n",
    "\n",
    "# On Redhawk : Each node has access to a GPU, so we don't need to specify a partition\n",
    "# srun demo_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px; border-color:black\"></hr>\n",
    "Reordering this output, we see how local block and thread indices are mapped to a global thread index.  Also note that print statements within a block are issued together, whereas the order among blocks is undefined. \n",
    "\n",
    "**Block 0**\n",
    "\n",
    "    Thread 0; Block 0 : Hello, World from global thread index 0\n",
    "    Thread 1; Block 0 : Hello, World from global thread index 1\n",
    "    Thread 2; Block 0 : Hello, World from global thread index 2\n",
    "    Thread 3; Block 0 : Hello, World from global thread index 3\n",
    "\n",
    "**Block 1**\n",
    "\n",
    "    Thread 0; Block 1 : Hello, World from global thread index 4\n",
    "    Thread 1; Block 1 : Hello, World from global thread index 5\n",
    "    Thread 2; Block 1 : Hello, World from global thread index 6\n",
    "    Thread 3; Block 1 : Hello, World from global thread index 7\n",
    "\n",
    "**Block 2**\n",
    "\n",
    "    Thread 0; Block 2 : Hello, World from global thread index 8\n",
    "    Thread 1; Block 2 : Hello, World from global thread index 9\n",
    "    Thread 2; Block 2 : Hello, World from global thread index 10\n",
    "    Thread 3; Block 2 : Hello, World from global thread index 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px; border-color:black\"></hr>\n",
    "We can pass arguments to kernels in the usual way.  Below, we also create a kernel that can be called from the device using the `__device__` designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting add.cu\n"
     ]
    }
   ],
   "source": [
    "%%file add.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "__device__ int addem( int a, int b ) \n",
    "{\n",
    "    return a + b;\n",
    "}\n",
    "\n",
    "__global__ void add( int a, int b, int *c ) \n",
    "{\n",
    "    *c = addem( a, b );\n",
    "}\n",
    "\n",
    "int main(void) \n",
    "{\n",
    "    int a,b,c;\n",
    "    int *dev_c;\n",
    "\n",
    "    /* Allocate memory on the device */\n",
    "    cudaMalloc( (void**)&dev_c, sizeof(int));\n",
    "\n",
    "    a = 2;\n",
    "    b = 7;\n",
    "    add<<<1,1>>>(a, b, dev_c );\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    /* Copy contents of dev_c back to c */\n",
    "    cudaMemcpy(&c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf( \"%d + %d = %d\\n\", a,b,c);\n",
    "\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 7 = 9\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "nvcc -o add add.cu\n",
    "\n",
    "# On R2 : \n",
    "srun -p gpuq add\n",
    "\n",
    "# On Redhawk\n",
    "# srun add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px; border-color:black\"></hr>\n",
    "\n",
    "We can also pass arrays to CUDA kernels and fill array entries just as we would do in a normal C program.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simple_parallel.cu\n"
     ]
    }
   ],
   "source": [
    "%%file simple_parallel.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void add( int *c) \n",
    "{\n",
    "    /* Since we have only one thread per block, the blockIdx and threadIdx are the same */\n",
    "    int id = blockIdx.x;  \n",
    "    c[id] = id;\n",
    "}\n",
    "\n",
    "int main(void) \n",
    "{\n",
    "    int N = 10;\n",
    "    \n",
    "    /* Allocate memory on the device */\n",
    "    int *dev_c;\n",
    "    cudaMalloc( (void**)&dev_c, N*sizeof(int));\n",
    "\n",
    "    /* Launch N thread blocks of 1 thread per block */\n",
    "    dim3 grid(N);  /* 1 x N array of blocks */\n",
    "    dim3 block(1); /* 1x1 thread block */\n",
    "    add<<<grid,block>>>(dev_c);\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    /* Copy contents of dev_c back to c */\n",
    "    int c[N];\n",
    "    cudaMemcpy( &c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    for(int i = 0; i < N; i++)\n",
    "    {\n",
    "        printf( \"c[%d] = %d\\n\",i,c[i]);\n",
    "    }\n",
    "\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c[0] = 0\n",
      "c[1] = 1\n",
      "c[2] = 2\n",
      "c[3] = 3\n",
      "c[4] = 4\n",
      "c[5] = 5\n",
      "c[6] = 6\n",
      "c[7] = 7\n",
      "c[8] = 8\n",
      "c[9] = 9\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "nvcc -o simple_parallel simple_parallel.cu\n",
    "\n",
    "srun -p gpuq simple_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
